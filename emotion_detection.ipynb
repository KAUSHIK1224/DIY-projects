{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPgIKe/WYZLDR+/WCKpA1Lj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAUSHIK1224/DIY-projects/blob/main/emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK9Xc03LSA3r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion Detection"
      ],
      "metadata": {
        "id": "03MXpaIRSB_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle opencv-python tensorflow"
      ],
      "metadata": {
        "id": "UFMJ85mXSFg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json when prompted"
      ],
      "metadata": {
        "id": "kJvl96bkSTcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "neMdc7wcSZIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d deadskull7/fer2013\n",
        "!unzip -q fer2013.zip -d /content/fer2013"
      ],
      "metadata": {
        "id": "QC8v3FmpSdCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_SIZE = (48, 48)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Load data from CSV\n",
        "df = pd.read_csv('/content/fer2013/fer2013.csv')\n",
        "\n",
        "# Convert pixels to image data and labels\n",
        "def preprocess_data(df):\n",
        "    X = []\n",
        "    y = []\n",
        "    for index, row in df.iterrows():\n",
        "        pixels = np.array(row['pixels'].split(), 'float32')\n",
        "        img = pixels.reshape(48, 48)\n",
        "        X.append(img)\n",
        "        y.append(row['emotion'])\n",
        "    X = np.array(X)\n",
        "    X = np.expand_dims(X, -1) # Add channel dimension for grayscale\n",
        "    y = tf.keras.utils.to_categorical(y, num_classes=7) # Assuming 7 emotion classes\n",
        "    return X, y\n",
        "\n",
        "X, y = preprocess_data(df)\n",
        "\n",
        "# Split data into train and test sets (manual split as CSV doesn't have separate folders)\n",
        "# Assuming 'Usage' column indicates train/test, if available. Otherwise, use train_test_split\n",
        "if 'Usage' in df.columns:\n",
        "    train_df = df[df['Usage'] == 'Training']\n",
        "    test_df = df[df['Usage'] == 'PublicTest'] # Assuming PublicTest is the test set\n",
        "\n",
        "    X_train, y_train = preprocess_data(train_df)\n",
        "    X_test, y_test = preprocess_data(test_df)\n",
        "\n",
        "    # Create ImageDataGenerators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Use flow from numpy arrays as we have preprocessed the data\n",
        "    train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "    test_generator = test_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE)\n",
        "\n",
        "else:\n",
        "    # If 'Usage' column is not available, use train_test_split\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "    test_generator = test_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Data generators created successfully.\")"
      ],
      "metadata": {
        "id": "2sBR_QMUSjRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kv9vM2w2S36R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_emotion_model.h5', monitor='val_accuracy', save_best_only=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=X_test.shape[0] // BATCH_SIZE,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "blmF00UiS8T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "def predict_emotion_cv(img_path, model, class_indices):\n",
        "    # Load image with OpenCV\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    label_map = {v: k for k, v in class_indices.items()}\n",
        "    for (x, y, w, h) in faces:\n",
        "        face = gray[y:y+h, x:x+w]\n",
        "        face_resized = cv2.resize(face, (48, 48))\n",
        "        face_normalized = face_resized / 255.0\n",
        "        face_input = np.expand_dims(face_normalized, axis=(0, -1))\n",
        "        prediction = model.predict(face_input)\n",
        "        emotion_idx = np.argmax(prediction)\n",
        "        emotion = label_map[emotion_idx]\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        cv2.putText(img, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "    # For Colab, use cv2_imshow\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    cv2_imshow(img)\n",
        "\n",
        "# Example usage:\n",
        "# predict_emotion_cv('/content/fer2013/test/happiness/123.jpg', model, train_generator.class_indices)"
      ],
      "metadata": {
        "id": "e66WIvWtU16l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss, acc = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {acc:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_9fqpDj6TlVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('emotion_cnn_final.h5')\n",
        "# To load later:\n",
        "# from tensorflow.keras.models import load_model\n",
        "# model = load_model('emotion_cnn_final.h5')"
      ],
      "metadata": {
        "id": "KvhZGRK2V8Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "v7qb10u3WB5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('emotion_cnn_final.h5')\n",
        "class_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
        "\n",
        "def predict_emotion(image):\n",
        "    # Convert to grayscale and resize\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    face = cv2.resize(gray, (48, 48))\n",
        "    face = face / 255.0\n",
        "    face = np.expand_dims(face, axis=(0, -1))\n",
        "    preds = model.predict(face)\n",
        "    emotion = class_labels[np.argmax(preds)]\n",
        "    return f\"Predicted Emotion: {emotion.capitalize()}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_emotion,\n",
        "    inputs=gr.Image(type=\"numpy\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Emotion Detection Dashboard\",\n",
        "    description=\"Upload a face image and the model will predict the emotion.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)  # share=True gives you a public link"
      ],
      "metadata": {
        "id": "lYFLBoZTWGi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f85242fc"
      },
      "source": [
        "!ls /content/fer2013"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}